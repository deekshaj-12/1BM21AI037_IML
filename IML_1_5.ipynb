{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "a = []\n",
    "with open('enjoysport.csv', 'r') as csvfile:\n",
    "    next(csvfile)\n",
    "    for row in csv.reader(csvfile):\n",
    "        a.append(row)\n",
    "    print(a)\n",
    "\n",
    "print(\"\\nThe total number of training instances are : \",len(a))\n",
    "\n",
    "num_attribute = len(a[0])-1\n",
    "\n",
    "print(\"\\nThe initial hypothesis is : \")\n",
    "hypothesis = ['0']*num_attribute\n",
    "print(hypothesis)\n",
    "\n",
    "for i in range(0, len(a)):\n",
    "    if a[i][num_attribute] == 'yes':\n",
    "        print (\"\\nInstance \", i+1, \"is\", a[i], \" and is Positive Instance\")\n",
    "        for j in range(0, num_attribute):\n",
    "            if hypothesis[j] == '0' or hypothesis[j] == a[i][j]:\n",
    "                hypothesis[j] = a[i][j]\n",
    "            else:\n",
    "                hypothesis[j] = '?'\n",
    "        print(\"The hypothesis for the training instance\", i+1, \" is: \" , hypothesis, \"\\n\")\n",
    "\n",
    "    if a[i][num_attribute] == 'no':\n",
    "        print (\"\\nInstance \", i+1, \"is\", a[i], \" and is Negative Instance Hence Ignored\")\n",
    "        print(\"The hypothesis for the training instance\", i+1, \" is: \" , hypothesis, \"\\n\")\n",
    "\n",
    "print(\"\\nThe Maximally specific hypothesis for the training instance is \", hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Candidate Elimination\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"enjoysport.csv\")\n",
    "concepts = np.array(data.iloc[:,0:-1])\n",
    "print(\"\\nInstances are:\\n\",concepts)\n",
    "target = np.array(data.iloc[:,-1])\n",
    "print(\"\\nTarget Values are: \",target)\n",
    "\n",
    "def learn(concepts, target):\n",
    "    specific_h = concepts[0].copy()\n",
    "    print(\"\\nInitialization of specific_h and genearal_h\")\n",
    "    print(\"\\nSpecific Boundary: \", specific_h)\n",
    "    general_h = [[\"?\" for i in range(len(specific_h))] for i in range(len(specific_h))]\n",
    "    print(\"\\nGeneric Boundary: \",general_h)\n",
    "\n",
    "    for i, h in enumerate(concepts):\n",
    "        print(\"\\nInstance\", i+1 , \"is \", h)\n",
    "        if target[i] == \"yes\":\n",
    "            print(\"Instance is Positive \")\n",
    "            for x in range(len(specific_h)):\n",
    "                if h[x]!= specific_h[x]:\n",
    "                    specific_h[x] ='?'\n",
    "                    general_h[x][x] ='?'\n",
    "\n",
    "        if target[i] == \"no\":\n",
    "            print(\"Instance is Negative \")\n",
    "            for x in range(len(specific_h)):\n",
    "                if h[x]!= specific_h[x]:\n",
    "                    general_h[x][x] = specific_h[x]\n",
    "                else:\n",
    "                    general_h[x][x] = '?'\n",
    "\n",
    "        print(\"Specific Bundary after \", i+1, \"Instance is \", specific_h)\n",
    "        print(\"Generic Boundary after \", i+1, \"Instance is \", general_h)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    indices = [i for i, val in enumerate(general_h) if val == ['?', '?', '?', '?', '?', '?']]\n",
    "    for i in indices:\n",
    "        general_h.remove(['?', '?', '?', '?', '?', '?'])\n",
    "    return specific_h, general_h\n",
    "\n",
    "s_final, g_final = learn(concepts, target)\n",
    "\n",
    "print(\"Final Specific_h: \", s_final, sep=\"\\n\")\n",
    "print(\"Final General_h: \", g_final, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.ID3\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "data = load_iris()\n",
    "X=data.data\n",
    "y=data.target\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y, test_size=0.25,random_state=42)\n",
    "classifier= DecisionTreeClassifier(criterion='entropy',random_state=0)\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.SVM\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "irisData = load_iris()\n",
    "X = irisData.data\n",
    "y = irisData.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "neighbors = np.arange(1, 10)\n",
    "train_accuracy = np.empty(len(neighbors))\n",
    "test_accuracy = np.empty(len(neighbors))\n",
    "for i, k in enumerate(neighbors):\n",
    "\tknn = KNeighborsClassifier(n_neighbors=k)\n",
    "\tknn.fit(X_train, y_train)\n",
    "\ttrain_accuracy[i] = knn.score(X_train, y_train)\n",
    "\ttest_accuracy[i] = knn.score(X_test, y_test)\n",
    "plt.plot(neighbors, test_accuracy, label = 'Testing dataset Accuracy')\n",
    "plt.plot(neighbors, train_accuracy, label = 'Training dataset Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('n_neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K nearest neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "irisData = load_iris()\n",
    "X = irisData.data\n",
    "y = irisData.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "neighbors = np.arange(1, 10)\n",
    "train_accuracy = np.empty(len(neighbors))\n",
    "test_accuracy = np.empty(len(neighbors))\n",
    "for i, k in enumerate(neighbors):\n",
    "\tknn = KNeighborsClassifier(n_neighbors=k)\n",
    "\tknn.fit(X_train, y_train)\n",
    "\ttrain_accuracy[i] = knn.score(X_train, y_train)\n",
    "\ttest_accuracy[i] = knn.score(X_test, y_test)\n",
    "plt.plot(neighbors, test_accuracy, label = 'Testing dataset Accuracy')\n",
    "plt.plot(neighbors, train_accuracy, label = 'Training dataset Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('n_neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
